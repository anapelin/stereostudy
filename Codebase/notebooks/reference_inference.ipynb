{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0978c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    Mask2FormerImageProcessor,\n",
    "    Mask2FormerForUniversalSegmentation,\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "# from trailvision.data import COCOWithVideo, AeroFeatureCollection\n",
    "\n",
    "\n",
    "task = \"panoptic\"\n",
    "model_size = \"base\"\n",
    "run_id = \"polygon\"\n",
    "\n",
    "# Configuration\n",
    "dataset_name = \"gQg5IUvV\"  # or \"OdnkTZQ8\"\n",
    "use_projected = True  # True for PROJECTED, False for RAW\n",
    "\n",
    "# Paths\n",
    "datasets_dir = Path(\"/data/common/STEREOSTUDYIPSL/Datasets\")\n",
    "dataset_dir = datasets_dir / dataset_name\n",
    "images_dir = dataset_dir / (\"PROJECTED\" if use_projected else \"RAW\")\n",
    "trailvision_dir = Path(\"/data/common/TRAILVISION\")\n",
    "segmentation_dir = trailvision_dir / \"segmentation\"\n",
    "models_dir = segmentation_dir / \"models\"\n",
    "altitude_ft = 10_000 / 0.3048\n",
    "\n",
    "# Load model from\n",
    "base_model = f\"facebook/mask2former-swin-{model_size}-coco-{task}\"  # Base model from Hugging Face\n",
    "checkpoint_dir = models_dir / task / run_id\n",
    "\n",
    "# Save predictions to\n",
    "predictions_dir = segmentation_dir / \"predictions\" / task / run_id / dataset_name\n",
    "\n",
    "# Get categories from model (simplified without COCO annotations)\n",
    "# You may need to adjust these categories based on your model training\n",
    "categories = [\n",
    "    {\"id\": 0, \"name\": \"object\", \"isthing\": 1},  # Generic object class\n",
    "    {\"id\": 1, \"name\": \"sky\", \"isthing\": 0},     # Background/sky\n",
    "]\n",
    "\n",
    "id2label = {id: label[\"name\"] for id, label in enumerate(categories)}\n",
    "\n",
    "# Image processor (normalization, resizing, etc.)\n",
    "processor = Mask2FormerImageProcessor.from_pretrained(\n",
    "    base_model,\n",
    "    do_resize=False,  # We handle resizing manually\n",
    "    do_rescale=False,  # We handle rescaling manually\n",
    "    do_normalize=True,  # Normalizes pixel values\n",
    "    do_reduce_labels=True,  # Decreases label indices by 1 (in COCO format labels start at 1)\n",
    "    ignore_index=255,  # Ignore label for padding/missing annotations\n",
    ")\n",
    "\n",
    "# Load model from checkpoint\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    id2label=id2label,  # Our custom class mapping\n",
    "    ignore_mismatched_sizes=True,  # Class numbers differs from COCO\n",
    ")\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# Remove all contents inside the directory if it exists\n",
    "if predictions_dir.exists() and predictions_dir.is_dir():\n",
    "    shutil.rmtree(predictions_dir)\n",
    "\n",
    "predictions_dir.mkdir(parents=True)\n",
    "\n",
    "print(f\"Processing images from: {images_dir}\")\n",
    "print(f\"Saving predictions to: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e97dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "kwargs[\"threshold\"] = 0.5\n",
    "kwargs[\"mask_threshold\"] = 0.5\n",
    "kwargs[\"overlap_mask_area_threshold\"] = 0.8\n",
    "kwargs[\"return_binary_maps\"] = True\n",
    "post_process_segmentation = processor.post_process_instance_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac952139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to parse timestamp from filename\n",
    "def parse_timestamp_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse timestamp from filename format: YYYYMMDDHHMMSS_XX.jpg\n",
    "    Example: 20250406044600_01.jpg -> 2025-04-06 04:46:00\n",
    "    \"\"\"\n",
    "    match = re.match(r'(\\d{14})_\\d{2}\\.jpg', filename)\n",
    "    if match:\n",
    "        timestamp_str = match.group(1)\n",
    "        return datetime.datetime.strptime(timestamp_str, '%Y%m%d%H%M%S')\n",
    "    return None\n",
    "\n",
    "# Get all image files\n",
    "image_files = sorted(list(images_dir.glob(\"*.jpg\")))\n",
    "print(f\"Found {len(image_files)} images\")\n",
    "\n",
    "# Group images by date (video sessions)\n",
    "videos = {}\n",
    "for img_path in image_files:\n",
    "    timestamp = parse_timestamp_from_filename(img_path.name)\n",
    "    if timestamp:\n",
    "        date_key = timestamp.strftime('%Y%m%d')\n",
    "        if date_key not in videos:\n",
    "            videos[date_key] = []\n",
    "        videos[date_key].append((img_path, timestamp))\n",
    "\n",
    "print(f\"Grouped into {len(videos)} video sessions: {list(videos.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22866297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each video session\n",
    "for date_key, images in tqdm(videos.items(), desc=\"Processing videos\"):\n",
    "    print(f\"\\nProcessing video session: {date_key}\")\n",
    "    \n",
    "    # Get start and end times for this video session\n",
    "    timestamps = [ts for _, ts in images]\n",
    "    video_start = min(timestamps)\n",
    "    video_stop = max(timestamps)\n",
    "    video_ref = f\"{video_start.strftime('%Y%m%d%H%M%S')}_{video_stop.strftime('%Y%m%d%H%M%S')}\"\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    for img_path, img_time in tqdm(images, desc=f\"  Images\", leave=False):\n",
    "        # Load image\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        \n",
    "        # Prepare inputs\n",
    "        inputs = processor([image], return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # Run inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        target_sizes = image.shape[:2]\n",
    "        \n",
    "        # Post-process segmentation\n",
    "        segmentation = post_process_segmentation(\n",
    "            outputs,\n",
    "            target_sizes=[target_sizes],\n",
    "            **kwargs,\n",
    "        )[0]\n",
    "        \n",
    "        # Store prediction with metadata\n",
    "        prediction = {\n",
    "            'filename': img_path.name,\n",
    "            'time': img_time,\n",
    "            'segmentation': segmentation,\n",
    "            'image_shape': image.shape[:2]\n",
    "        }\n",
    "        all_predictions.append(prediction)\n",
    "    \n",
    "    # Save predictions for this video session\n",
    "    out_file = (predictions_dir / video_ref).with_suffix(\".npz\")\n",
    "    \n",
    "    # Convert to saveable format\n",
    "    save_data = {\n",
    "        'video_start': video_start.isoformat(),\n",
    "        'video_stop': video_stop.isoformat(),\n",
    "        'filenames': [p['filename'] for p in all_predictions],\n",
    "        'timestamps': [p['time'].isoformat() for p in all_predictions],\n",
    "    }\n",
    "    \n",
    "    # Save segmentation masks separately for each image\n",
    "    for i, pred in enumerate(all_predictions):\n",
    "        seg = pred['segmentation']\n",
    "        if 'segmentation' in seg:\n",
    "            save_data[f'mask_{i}'] = seg['segmentation'].cpu().numpy()\n",
    "        if 'segments_info' in seg:\n",
    "            save_data[f'segments_info_{i}'] = str(seg['segments_info'])\n",
    "    \n",
    "    np.savez_compressed(out_file, **save_data)\n",
    "    print(f\"  Saved {len(all_predictions)} predictions to {out_file.name}\")\n",
    "\n",
    "print(f\"\\nProcessing complete! Results saved to: {predictions_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
